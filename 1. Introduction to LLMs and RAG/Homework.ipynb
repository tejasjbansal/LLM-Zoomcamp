{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eebe3de-9a93-49bf-86bd-abfe9177f75a",
   "metadata": {},
   "source": [
    "# Question 1. Running Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326a761e-24ad-4e11-8902-25531258728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Search Index\n",
    "\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e28cd6-caca-424d-a838-4b1f67f73a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58dfec2-9065-4ffe-8263-a4f50e6cd84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42f05b9372a9a4a470db3b52817899b99a76ee73'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()['version']['build_hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd2d7cb-2e00-4892-9ac1-40c63156cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a8f046-1e67-4367-b5fe-ee976a72048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f89015-5f11-4149-8970-9b3870913d58",
   "metadata": {},
   "source": [
    "# Q2. Indexing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c0a4d1-b055-49c9-a2b2-bb8561784e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'homework-course-questions'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"homework-course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name,body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "368c523e-8f11-45f6-a8f8-8a8b4c1a26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983bf1b3-8b59-4dec-8097-78a39bb2cdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:26<00:00, 35.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name,document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0e517-b9ea-440a-9d65-dbcdbeed8502",
   "metadata": {},
   "source": [
    "# Q3. Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6742e81-d867-400d-b243-fe0a657aa331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_to_score(query):\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=index_name,body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_score'])\n",
    "\n",
    "    return result_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c7fd481-75fa-4586-bd60-e90a54fb5186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[84.050095, 51.04628, 49.938507, 45.275463, 45.255775]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "elastic_search_to_score(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3f0ff-22f6-41cb-b081-9cb9b4229538",
   "metadata": {},
   "source": [
    "# Q4. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d74f6b67-8b94-4943-9f34-aef3308bccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=index_name,body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e4dbadd-e8e2-4d55-b380-c9d8b04598f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How do I debug a docker container?\",\n",
    "\"How do I copy files from a different folder into docker container’s working directory?\",\n",
    "\"How do Lambda container images work?\",\n",
    "\"How can I annotate a graph?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a72f8c34-34d8-4f28-b982-0910bd96a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "\n",
    "for q in questions:\n",
    "    answers.append(elastic_search(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "735d7378-d12e-4a25-a5fe-3cc07abb37ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'I wanted to understand how lambda container images work in depth and how lambda functions are initialized, for this reason, I found the following documentation\\nhttps://docs.aws.amazon.com/lambda/latest/dg/images-create.html\\nhttps://docs.aws.amazon.com/lambda/latest/dg/runtimes-api.html\\nAdded by Alejandro aponte', 'section': '9. Serverless Deep Learning', 'question': 'How do Lambda container images work?', 'course': 'machine-learning-zoomcamp'}, {'text': 'Tim from BentoML has prepared a dedicated video tutorial wrt this use case here:\\nhttps://www.youtube.com/watch?v=7gI1UH31xb4&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=97\\nKonrad Muehlberg', 'section': 'Miscellaneous', 'question': 'How to pass BentoML content / docker container to Amazon Lambda', 'course': 'machine-learning-zoomcamp'}, {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)', 'section': '5. Deploying Machine Learning Models', 'question': 'How do I debug a docker container?', 'course': 'machine-learning-zoomcamp'}]\n"
     ]
    }
   ],
   "source": [
    "print(answers[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416bcc7-f852-483d-b082-7d9123a86d9f",
   "metadata": {},
   "source": [
    "# Q5. Building a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e200c3b6-dc81-406f-9db5-5c673c0e847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question,search_results):\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=question, context=context).strip()\n",
    "    print(\"Length of the Prompt : \",len(prompt))\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a563e755-88ca-45a1-abbb-5c469dfe82db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the Prompt :  1660\n"
     ]
    }
   ],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "search_results = elastic_search(query)\n",
    "prompt = build_prompt(query,search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11a9ef-a261-4d97-a89f-d766e6d80dbe",
   "metadata": {},
   "source": [
    "# Q6. Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "208b254c-9162-4776-b2f1-5561f98eee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47c31051-77c1-4de1-93dc-d9bee458ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf027369-a8b6-4d75-bd2f-4abc4c8fa475",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94becf86-4634-4d18-9ac1-019747632c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 361\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(prompt)\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35ada1-9650-4017-a09e-dc2a2e61299b",
   "metadata": {},
   "source": [
    "# Bonus: generating the answer (ungraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f03a4479-3a09-4670-a08a-907210eca790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def llm(prompt):\n",
    "    # load environment variables\n",
    "    load_dotenv()\n",
    "    \n",
    "    # create client calling Groq class\n",
    "    client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "    \n",
    "    # create a query\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    \n",
    "    # print the response\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ae212c4-7789-4768-9b6a-634782cf1076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, to execute a command in a running Docker container, you need to:\n",
      "\n",
      "1. Find the container ID by running `docker ps`.\n",
      "2. Execute the command using `docker exec -it <container-id> bash`.\n",
      "\n",
      "This will open a new interactive bash session within the running Docker container, allowing you to execute commands.\n"
     ]
    }
   ],
   "source": [
    "answer = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148ca87-2181-4d08-b368-96639b287b54",
   "metadata": {},
   "source": [
    "# Bonus: calculating the costs (ungraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f16e7a5b-bde1-4dde-80c2-1c0d0a87bd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost to run 1000 requests: $4.50\n"
     ]
    }
   ],
   "source": [
    "# Define the given data\n",
    "tokens_per_request_input = 150\n",
    "tokens_per_request_output = 250\n",
    "number_of_requests = 1000\n",
    "cost_per_1k_tokens_input = 0.005\n",
    "cost_per_1k_tokens_output = 0.015\n",
    "\n",
    "# Calculate the total tokens for 1000 requests\n",
    "total_tokens_input = tokens_per_request_input * number_of_requests\n",
    "total_tokens_output = tokens_per_request_output * number_of_requests\n",
    "\n",
    "# Calculate the cost of the input tokens\n",
    "cost_input_tokens = (total_tokens_input / 1000) * cost_per_1k_tokens_input\n",
    "\n",
    "# Calculate the cost of the output tokens\n",
    "cost_output_tokens = (total_tokens_output / 1000) * cost_per_1k_tokens_output\n",
    "\n",
    "# Calculate the total cost\n",
    "total_cost = cost_input_tokens + cost_output_tokens\n",
    "\n",
    "# Output the result\n",
    "print(f\"Total cost to run {number_of_requests} requests: ${total_cost:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
